{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sabaneriddhi/Text-Summarizer/blob/main/Text_Summaizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "e_dBKlWDORIY"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load(\"en_core_web_sm\")\n"
      ],
      "metadata": {
        "id": "DDyeWiOPPnLA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text= input(\"Enter text you want to summarize\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqWnY10_QKvR",
        "outputId": "345a11dc-cb3c-4d9f-aab6-2858f1469ec7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter text you want to summarize\n",
            "Deep learning is part of a broader family of machine learning methods, which is based on artificial neural networks with representation learning. The adjective \"deep\" in deep learning refers to the use of multiple layers in the network. Methods used can be either supervised, semi-supervised or unsupervised.  Deep-learning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks, convolutional neural networks and transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.Artificial neural networks (ANNs) were inspired by information processing and distributed communication nodes in biological systems. ANNs have various differences from biological brains. Specifically, artificial neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) and analog.Deep learning is a class of machine learning algorithms that[8]: 199–200  uses multiple layers to progressively extract higher-level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits or letters or faces.From another angle to view deep learning, deep learning refers to ‘computer-simulate’ or ‘automate’ human learning processes from a source (e.g., an image of dogs) to a learned object (dogs). Therefore, a notion coined as “deeper” learning or “deepest” learning [9] makes sense. The deepest learning refers to the fully automatic learning from a source to a final learned object. A deeper learning thus refers to a mixed learning process: a human learning process from a source to a learned semi-object, followed by a computer learning process from the human learned semi-object to a final learned object.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp(input_text)"
      ],
      "metadata": {
        "id": "iQG1JxKTQ-wq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training using Pegasus\n",
        "\n",
        "!pip install transformers\n",
        "\n",
        "from transformers import PegasusForConditionalGeneration,PegasusTokenizer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kw8QTAwSRJ_F",
        "outputId": "b42ed866-8e92-4109-8f54-fbe922a74a96"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SentencePiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tozc-xTRTHqW",
        "outputId": "e20122ad-7ebc-4096-be59-b9dad8411f2a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SentencePiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name=\"google/pegasus-xsum\"\n",
        "\n",
        "pegasus_tokenizer=PegasusTokenizer.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "qyA8lUXCSXZb"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Pegasus model\n",
        "\n",
        "pegasus_model=PegasusForConditionalGeneration.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6m7OMOVUM0h",
        "outputId": "f49ee3ad-41fc-41b3-8a50-6fd6607240c4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create tokens\n",
        "\n",
        "tokens=pegasus_tokenizer(input_text,truncation=True,padding=\"longest\",return_tensors=\"pt\")\n",
        "\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEFZO0WIU_JM",
        "outputId": "3fd0da57-d75a-44ad-80b1-e6405bfe5530"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 7496,   761,   117,   297,   113,   114,  7792,   328,   113,  1157,\n",
              "           761,  1625,   108,   162,   117,   451,   124,  4958, 14849,  3296,\n",
              "           122,  5114,   761,   107,   139, 42164,   198, 18007,   194,   115,\n",
              "          1355,   761,  6335,   112,   109,   207,   113,  1079,  4427,   115,\n",
              "           109,   952,   107, 18508,   263,   137,   129,   707, 15561,   108,\n",
              "          3964,   121, 83465,   132, 53744,   107,  7496,   121, 13049, 31576,\n",
              "           253,   130,  1355, 14849,  3296,   108,  1355,  4936,  3296,   108,\n",
              "          1355, 19189,   761,   108, 27441, 14849,  3296,   108, 76284,  1114,\n",
              "         14849,  3296,   111, 40749,   133,   174,  2140,   112,  2574,   330,\n",
              "           958,  1942,   108,  3442,  3771,   108,   710,  1261,  2196,   108,\n",
              "          1157,  5256,   108, 65237,   108,  2108,   354,   108,   941,   805,\n",
              "          1382,   108,  2354,  1578,   108,  1001,  4323,   111,  1042,   389,\n",
              "           962,   108,   241,   157,   133,  1788,   602,  8575,   112,   111,\n",
              "           115,   181,  1145, 44144,   883,  1766,   637,   107, 50652, 14849,\n",
              "          3296,   143, 45884,   116,   158,   195,  2261,   141,   257,  2196,\n",
              "           111,  4918,  1660, 11406,   115,  7777,   747,   107,   110, 45884,\n",
              "           116,   133,   623,  3888,   135,  7777, 13666,   107, 16736,   108,\n",
              "          4958, 14849,  3296,  2509,   112,   129,  7822,   111, 14967,   108,\n",
              "           277,   109,  7777,  2037,   113,   205,   622, 14800,   117,  3248,\n",
              "           143, 19835,   158,   111, 11901,   107, 21161,   761,   117,   114,\n",
              "           755,   113,  1157,   761,  8970,   120,  4101,  2000, 37726, 37665,\n",
              "          1198,  6704,  1481,  1079,  4427,   112, 23398,  5703,   902,   121,\n",
              "          3393,   556,   135,   109,  3492,  3196,   107,   321,   587,   108,\n",
              "           115,   805,  2196,   108,  1074,  4427,   218,  1956,  5198,   108,\n",
              "           277,   902,  4427,   218,  1956,   109,  3924,  1862,   112,   114,\n",
              "           883,   253,   130, 15865,   132,  3439,   132,  4121,   107,  2378,\n",
              "           372,  4962,   112,   700,  1355,   761,   108,  1355,   761,  6335,\n",
              "           112,   402, 24146,   121, 21181, 26557,   123,   132,   402, 17994,\n",
              "         12210,   123,   883,   761,  1994,   135,   114,  1116,   143,   326,\n",
              "           107,   838,   107,   108,   142,   805,   113,  2457,   158,   112,\n",
              "           114,  1800,  2951,   143, 45201,   250,  3272,   108,   114,  8642,\n",
              "         27775,   130,   185, 18007,   420,   227,   761,   132,   185, 18007,\n",
              "          4830,   227,   761,  1126, 76207,   493,  1083,   107,   139, 15699,\n",
              "           761,  6335,   112,   109,  1069,  3938,   761,   135,   114,  1116,\n",
              "           112,   114,   976,  1800,  2951,   107,   202,  4190,   761,  2297,\n",
              "          6335,   112,   114,  3044,   761,   366,   151,   114,   883,   761,\n",
              "           366,   135,   114,  1116,   112,   114,  1800,  3964,   121, 30990,\n",
              "           108,  1734,   141,   114,   958,   761,   366,   135,   109,   883,\n",
              "          1800,  3964,   121, 30990,   112,   114,   976,  1800,  2951,   107,\n",
              "             1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_summary=pegasus_model.generate(**tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jZsAIOMVciz",
        "outputId": "e2ba9c11-2ed2-40b5-f9c0-b82ed0b9159b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (64) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#decode summary\n",
        "\n",
        "decoded_summary = pegasus_tokenizer.decode(encoded_summary[0], skip_special_tokens = True)\n",
        "\n",
        "decoded_summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "C5Q-PLw4VydP",
        "outputId": "1deef089-f893-4875-f91c-18f98ac10bcc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Deep learning is a branch of machine learning that aims to improve the performance of computers on a wide range of tasks.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import summarization pipeline from hugging face\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=model_name, tokenizer = pegasus_tokenizer, framework=\"pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpBv4xG4WOGY",
        "outputId": "6102fbfc-04df-4da1-da44-0a3ff092b277"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create summary\n",
        "\n",
        "summary = summarizer(input_text, min_length=30, max_length=150)"
      ],
      "metadata": {
        "id": "R7LcuJfCXAwT"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "rQdvsuSoXfBs",
        "outputId": "c69c8115-854f-41de-a4f1-93c0f35eb20d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Deep learning is part of a broader family of machine learning methods, which is based on artificial neural networks with representation learning. The adjective \"deep\" in deep learning refers to the use of multiple layers in the network. Methods used can be either supervised, semi-supervised or unsupervised.  Deep-learning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks, convolutional neural networks and transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.Artificial neural networks (ANNs) were inspired by information processing and distributed communication nodes in biological systems. ANNs have various differences from biological brains. Specifically, artificial neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) and analog.Deep learning is a class of machine learning algorithms that[8]:\\u200a199–200\\u200a uses multiple layers to progressively extract higher-level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits or letters or faces.From another angle to view deep learning, deep learning refers to ‘computer-simulate’ or ‘automate’ human learning processes from a source (e.g., an image of dogs) to a learned object (dogs). Therefore, a notion coined as “deeper” learning or “deepest” learning [9] makes sense. The deepest learning refers to the fully automatic learning from a source to a final learned object. A deeper learning thus refers to a mixed learning process: a human learning process from a source to a learned semi-object, followed by a computer learning process from the human learned semi-object to a final learned object.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary[0][\"summary_text\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "jEWHV2_NXhXD",
        "outputId": "82bcbfc3-90f3-492b-96ea-6fbac2f66942"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Deep learning is a branch of machine learning that aims to improve the performance of computers on a wide range of tasks, including image processing, speech recognition, natural language processing, drug design, medical image analysis, climate science, material inspection and board game programs.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDwWD2XNlQp1S0k6Dk+y5d",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}